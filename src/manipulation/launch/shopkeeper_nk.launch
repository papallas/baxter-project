<launch>

<!-- Copied roslaunch mary_tts file into here to setup the voice-->
<arg name="machine" default="localhost" />
<arg name="user" default="" />

<machine name="$(arg machine)" address="$(arg machine)" env-loader="$(optenv ROS_ENV_LOADER )" user="$(arg user)" default="false"/>

<node name="maryserver" pkg="mary_tts" type="marytts-server.sh" cwd="node" machine="$(arg machine)"/>
<node name="ros_mary_bridge" pkg="mary_tts" type="marybridge.py" respawn="true">
    <param name="voice" value="$(optenv TTS_VOICE dfki-spike-hsmm)" type="string"/>
          <param name="locale" value="$(optenv TTS_LOCALE en_GB)" type="string"/>
    <param name="host" value="$(arg machine)" type="string"/>
</node>

<!-- Move Baxter's arms to the untucked position and setup the cameras at the correct resolutions-->
<node pkg="baxter_tools" type="camera_control.py" name="right_camera_setup" args="-o right_hand_camera -r 1280x800"/>
<node pkg="baxter_tools" type="camera_control.py" name="left_camera_setup" args="-c left_hand_camera"/>
<node pkg="baxter_tools" type="camera_control.py" name="head_camera_setup" args="-o head_camera -r 480x300"/> -->
<node pkg="baxter_tools" type="tuck_arms.py" name="tuck_arms" args="-u"/>

<!-- Run the shopkeeper node without Kinect -->
<node pkg="manipulation" type="robot_shopkeeper_nk.py" name="shopkeeper" output="screen"/>

<!-- Run the vision system to detect the sweets on the page -->
<node pkg="perception" type="find_colours.py" name="find_sweets"/>

<!-- Run the human interaction system listen for commands and recognise customers -->
<node pkg="interaction" type="app_server.py" name="app_server" output="screen"/>
<node pkg="interaction" type="find_person.py" name="find_person" output="screen"/>

</launch>
